{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb77d46d-544d-41a9-a04b-44191acc30fc",
   "metadata": {},
   "source": [
    "# This notebook illustrates the Gaussian Process Regression, in 2D search region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f99378-56eb-4c9d-ae85-e51e32f8bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from jax import numpy as jnp\n",
    "from jax import jit, grad,vmap\n",
    "from InfoGrad import InfoGrad\n",
    "from time import time\n",
    "import pickle as pkl\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be37b370-12b3-4fa5-b0d0-90f0c243b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The underlying function\n",
    "def f(P):\n",
    "    X = P[:,0]\n",
    "    Y = P[:,1]\n",
    "    return -(np.exp(-2*(X+1.5)**2 - 0.3*(Y+1.5)**2-0.3*X*Y+0.4)+np.exp(-(X-0.5)**2 - (Y-1.2)**2-0.6*X*Y)+np.exp(-0.7*(X-1.5)**2 - 0.3*(Y+1.5)**2-0.*X*Y))\n",
    "\n",
    "# The differentiable kernel function with parameters c,l not filled.\n",
    "def k(x1,x2,c,l):\n",
    "    small_sig = 1e-10 # This is needed for numerical stability.\n",
    "    return c * jnp.exp(-(jnp.linalg.norm(x1-x2+small_sig,axis = -1)**2) / l)\n",
    "\n",
    "def f_sampler(X):\n",
    "    Y = f(X)\n",
    "    return Y+np.random.randn(*Y.shape)*0.1\n",
    "\n",
    "def random_sample_locs(n_locs,dim_lims):\n",
    "    '''\n",
    "        dim_lims = [(u1,l1),(u2,l2),...,(u{space_dim},l{space_dim})]\n",
    "    '''\n",
    "    return (np.random.rand(n_locs, len(dim_lims)))*(dim_lims[:,-1]-dim_lims[:,0]) + dim_lims[:,0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfbb8b4b-ee6e-4fec-a999-b8416705c8b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient calc time 0.7297458648681641\n",
      "model fit time 0.3482632637023926\n",
      "Gradient calc time 0.40169644355773926\n",
      "model fit time 0.2989614009857178\n",
      "Gradient calc time 0.3077123165130615\n",
      "model fit time 0.33503031730651855\n",
      "Gradient calc time 0.32546019554138184\n",
      "model fit time 0.38565683364868164\n",
      "Gradient calc time 0.38106560707092285\n",
      "model fit time 0.3753962516784668\n",
      "Gradient calc time 0.4149439334869385\n",
      "model fit time 0.35867857933044434\n",
      "Gradient calc time 0.5149393081665039\n",
      "model fit time 0.2997457981109619\n",
      "Gradient calc time 0.3747680187225342\n",
      "model fit time 0.3049602508544922\n",
      "Gradient calc time 0.4459233283996582\n",
      "model fit time 0.28008008003234863\n",
      "Gradient calc time 0.33914613723754883\n",
      "model fit time 0.3429591655731201\n",
      "Gradient calc time 0.4314994812011719\n",
      "model fit time 0.3582456111907959\n",
      "Gradient calc time 0.46437692642211914\n",
      "model fit time 0.42131972312927246\n",
      "Gradient calc time 0.3666725158691406\n",
      "model fit time 0.4370710849761963\n",
      "Gradient calc time 0.5462911128997803\n",
      "model fit time 0.5338973999023438\n",
      "Gradient calc time 0.517798900604248\n",
      "model fit time 0.4842414855957031\n",
      "Gradient calc time 0.4150388240814209\n",
      "model fit time 0.4445476531982422\n",
      "Gradient calc time 0.516437292098999\n",
      "model fit time 0.4466419219970703\n",
      "Gradient calc time 0.3531348705291748\n",
      "model fit time 0.4898245334625244\n",
      "Gradient calc time 0.4842357635498047\n",
      "model fit time 0.4678201675415039\n",
      "Gradient calc time 0.5267565250396729\n",
      "model fit time 0.44970178604125977\n",
      "Gradient calc time 0.4430675506591797\n",
      "model fit time 0.45249366760253906\n",
      "Gradient calc time 0.5134215354919434\n",
      "model fit time 0.4646768569946289\n",
      "Gradient calc time 0.6517701148986816\n",
      "model fit time 0.5359225273132324\n",
      "Gradient calc time 0.49268293380737305\n",
      "model fit time 0.6122698783874512\n",
      "Gradient calc time 0.5527505874633789\n",
      "model fit time 0.6292574405670166\n",
      "Gradient calc time 0.4227561950683594\n",
      "model fit time 0.7100527286529541\n",
      "Gradient calc time 0.5417113304138184\n",
      "model fit time 0.7510204315185547\n",
      "Gradient calc time 0.542675256729126\n",
      "model fit time 0.6548950672149658\n",
      "Gradient calc time 0.45206403732299805\n",
      "model fit time 0.621861457824707\n",
      "Gradient calc time 0.5154221057891846\n",
      "model fit time 0.6838760375976562\n",
      "Gradient calc time 0.583319902420044\n",
      "model fit time 0.7232024669647217\n",
      "Gradient calc time 0.5985362529754639\n",
      "model fit time 0.7262876033782959\n",
      "Gradient calc time 0.5932958126068115\n",
      "model fit time 0.9021792411804199\n",
      "Gradient calc time 0.48252296447753906\n",
      "model fit time 0.7281372547149658\n",
      "Gradient calc time 0.5962033271789551\n",
      "model fit time 0.7350401878356934\n",
      "Gradient calc time 0.6657686233520508\n",
      "model fit time 0.7564547061920166\n",
      "Gradient calc time 0.39791250228881836\n",
      "model fit time 0.9510750770568848\n",
      "Gradient calc time 0.46516942977905273\n",
      "model fit time 0.7872264385223389\n",
      "Gradient calc time 0.542499303817749\n",
      "model fit time 0.7872638702392578\n",
      "Gradient calc time 0.43122196197509766\n",
      "model fit time 0.8259725570678711\n",
      "Gradient calc time 0.49026918411254883\n",
      "model fit time 0.8605837821960449\n",
      "Gradient calc time 0.40038156509399414\n",
      "model fit time 0.878206729888916\n",
      "Gradient calc time 0.46965765953063965\n",
      "model fit time 0.8781585693359375\n",
      "Gradient calc time 0.47235631942749023\n",
      "model fit time 0.8048226833343506\n",
      "Gradient calc time 0.44969725608825684\n",
      "model fit time 0.8224906921386719\n",
      "Gradient calc time 0.48897433280944824\n",
      "model fit time 0.8540356159210205\n",
      "Gradient calc time 0.5410201549530029\n",
      "model fit time 0.878392219543457\n",
      "Gradient calc time 0.5102002620697021\n",
      "model fit time 1.141660451889038\n",
      "Gradient calc time 0.5594496726989746\n",
      "model fit time 0.9334392547607422\n",
      "Gradient calc time 0.4087800979614258\n",
      "model fit time 0.9769084453582764\n",
      "InfoGrad 49 time: 56.24878740310669\n",
      "Gradient calc time 0.2859203815460205\n",
      "model fit time 0.2145228385925293\n",
      "Gradient calc time 0.23245954513549805\n",
      "model fit time 0.2534303665161133\n",
      "Gradient calc time 0.21879124641418457\n",
      "model fit time 0.31882500648498535\n",
      "Gradient calc time 0.296677827835083\n",
      "model fit time 0.28426361083984375\n",
      "Gradient calc time 0.2427520751953125\n",
      "model fit time 0.3326852321624756\n",
      "Gradient calc time 0.2928955554962158\n",
      "model fit time 0.3619227409362793\n",
      "Gradient calc time 0.37571191787719727\n",
      "model fit time 0.3442094326019287\n",
      "Gradient calc time 0.26578688621520996\n",
      "model fit time 0.37769174575805664\n",
      "Gradient calc time 0.4244043827056885\n",
      "model fit time 0.4455859661102295\n",
      "Gradient calc time 0.27509403228759766\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_59183/4178169603.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoisy_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model fit time'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'greedy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    270\u001b[0m             optima = [\n\u001b[1;32m    271\u001b[0m                 (\n\u001b[0;32m--> 272\u001b[0;31m                     self._constrained_optimization(\n\u001b[0m\u001b[1;32m    273\u001b[0m                         \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     )\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36m_constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_constrained_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fmin_l_bfgs_b\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             opt_res = scipy.optimize.minimize(\n\u001b[0m\u001b[1;32m    604\u001b[0m                 \u001b[0mobj_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0minitial_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                   **options)\n\u001b[1;32m    622\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    624\u001b[0m                                 callback=callback, **options)\n\u001b[1;32m    625\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mobj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mobj_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                     lml, grad = self.log_marginal_likelihood(\n\u001b[0m\u001b[1;32m    263\u001b[0m                         \u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclone_kernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     )\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/sklearn/gaussian_process/_gpr.py\u001b[0m in \u001b[0;36mlog_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mlog_likelihood_dims\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# the log likehood is sum-up across the outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mlog_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_likelihood_dims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_gradient\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/simulation/lib/python3.9/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     47\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "space_dim = 2\n",
    "step_size = 0.2\n",
    "n_test = 100\n",
    "D  = 1\n",
    "dim_lims = np.array([(-D,D),(-D,D)])\n",
    "var_0  = 0.01\n",
    "N_iteration = 50\n",
    "N_trials = 10\n",
    "\n",
    "xlist = np.linspace(-D, D, 100)\n",
    "ylist = np.linspace(-D, D, 100)\n",
    "full_X = np.meshgrid(xlist, ylist)\n",
    "full_X = np.hstack([full_X[0].reshape(-1,1),full_X[1].reshape(-1,1)])\n",
    "\n",
    "\n",
    "X_0 = np.array([-1,1,\n",
    "              0,0,\n",
    "              1,1,\n",
    "              1,-1,\n",
    "              -1,-1]).reshape(-1,space_dim)\n",
    "\n",
    "Y_0 =  f_sampler(X_0)\n",
    "random_states = np.random.randint(0,10000,N_trials)\n",
    "# for mode in ['greedy','InfoGrad','randomWalk']:\n",
    "for mode in ['InfoGrad','randomWalk']:\n",
    "    \n",
    "    # mode = 'InfoGrad'\n",
    "    # mode = 'randomWalk'\n",
    "    \n",
    "    data = {}\n",
    "    data['mu_hist'] = []\n",
    "    data['std_hist'] = []\n",
    "    data['X'] = []\n",
    "    data['noisy_Y'] = []\n",
    "    data['n_0'] = []\n",
    "    data['n_robot'] = []\n",
    "    for _ in range(N_trials):\n",
    "        \n",
    "        X = np.array(X_0)\n",
    "        noisy_Y = np.array(Y_0)\n",
    "\n",
    "\n",
    "        kernel = C(1.0, (1e-3, 1e3)) * RBF(100, (1e-6, 1e6))\n",
    "\n",
    "        model = GPR(kernel,alpha = var_0,n_restarts_optimizer=20,random_state = random_states[_])\n",
    "\n",
    "#         model = GPR(kernel,alpha = var_0,optimizer= None)\n",
    "\n",
    "        model.fit(X,noisy_Y)\n",
    "\n",
    "        curr_x = np.array([0.1,0,-0.1,0,0,-0.1]).reshape(-1,space_dim)\n",
    "\n",
    "        gradCalc = InfoGrad(k)\n",
    "\n",
    "        n_0 = len(X)\n",
    "        \n",
    "\n",
    "        x_hist = []\n",
    "\n",
    "        mu_hist = []\n",
    "\n",
    "        std_hist = []\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        t = time()\n",
    "        for n in range(N_iteration):\n",
    "            \n",
    "            mu,std= model.predict(full_X.reshape(-1,space_dim),return_std=True)\n",
    "            mu = mu.flatten()\n",
    "\n",
    "            mu_hist.append(mu)\n",
    "            std_hist.append(std)\n",
    "            \n",
    "            new_x = []\n",
    "            if mode == 'InfoGrad':\n",
    "    #             dx=0.1\n",
    "                \n",
    "                t_start = time()\n",
    "                dx = gradCalc.dIdx(model,curr_x,X.reshape(-1,space_dim)).reshape(curr_x.shape)\n",
    "                print('Gradient calc time',time()-t_start)\n",
    "\n",
    "                new_x = curr_x + (dx/np.linalg.norm(dx)) * step_size + np.random.randn(*curr_x.shape)*0.1 # Add some stochasticity to shake away from the corners.\n",
    "\n",
    "                new_x = np.array(new_x)\n",
    "                new_x[new_x>D] = D\n",
    "                new_x[new_x<-D] = -D\n",
    "\n",
    "                # Collect new data\n",
    "                new_y = f_sampler(new_x)\n",
    "\n",
    "                # Model update is mandatory, as required by sklearn.GPR\n",
    "\n",
    "                X = np.vstack([X,new_x])\n",
    "                noisy_Y = np.hstack([noisy_Y,new_y])\n",
    "                \n",
    "                t_start = time()\n",
    "                model.fit(X,noisy_Y)\n",
    "                print('model fit time',time()-t_start)\n",
    "            elif mode == 'greedy':\n",
    "\n",
    "                for i in range(len(curr_x)):\n",
    "\n",
    "                    x_test = random_sample_locs(n_test,dim_lims)\n",
    "\n",
    "                    _,std = model.predict(x_test,return_std = True)\n",
    "\n",
    "                    x_dest = x_test[np.argmax(std)]\n",
    "\n",
    "                    x_next = curr_x[i] + step_size * (x_dest-curr_x[i])/np.linalg.norm(x_dest-curr_x[i])\n",
    "\n",
    "                    x_next[x_next>D] = D\n",
    "                    x_next[x_next<-D] = -D\n",
    "\n",
    "                    y_next = f_sampler(x_next.reshape(-1,space_dim)).flatten()\n",
    "\n",
    "                    new_x.append(x_next)\n",
    "\n",
    "                    # Model update is mandatory, as required by sklearn.GPR\n",
    "\n",
    "                    X = np.vstack([X,x_next])\n",
    "                    noisy_Y = np.hstack([noisy_Y,y_next])\n",
    "\n",
    "                    model.fit(X,noisy_Y)\n",
    "            elif mode == 'randomWalk':\n",
    "    #             new_x = random_sample_locs(1,np.hstack([curr_x+step_size,curr_x-step_size]).T).reshape(curr_x.shape)\n",
    "                new_x = random_sample_locs(1,np.hstack([curr_x+step_size,curr_x-step_size]).reshape(-1,space_dim)).reshape(curr_x.shape)\n",
    "                new_x = np.array(new_x)\n",
    "                new_x[new_x>D] = D\n",
    "                new_x[new_x<-D] = -D\n",
    "\n",
    "\n",
    "\n",
    "                 # Collect new data\n",
    "                new_y = f_sampler(new_x)\n",
    "\n",
    "                # Model update is mandatory, as required by sklearn.GPR\n",
    "\n",
    "                X = np.vstack([X,new_x])\n",
    "                noisy_Y = np.hstack([noisy_Y,new_y])\n",
    "\n",
    "                model.fit(X,noisy_Y)\n",
    "            else:\n",
    "                print('Mode {} does not exist.'.format(mode))\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "            # Update curr_x\n",
    "\n",
    "            curr_x = np.array(new_x)\n",
    "\n",
    "#             x_hist.append(np.array(new_x))\n",
    "\n",
    "    \n",
    "            \n",
    "        \n",
    "        print(mode,n,'time:',time()-t)\n",
    "        data['mu_hist'].append(mu_hist)\n",
    "        data['std_hist'].append(std_hist)\n",
    "        data['X'].append(X)\n",
    "        data['noisy_Y'].append(noisy_Y)\n",
    "        data['n_0'].append(n_0)\n",
    "        data['n_robot'].append(curr_x)\n",
    "\n",
    "    with open('{}2D-REP.pkl'.format(mode),'wb') as file:\n",
    "        pkl.dump(data,file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
